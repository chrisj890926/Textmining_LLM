{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VYEacS6QXUC_v0-E2i_7CJeKy-jP8OgH",
      "authorship_tag": "ABX9TyNxRfay32/3kU0zEPfiCodF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEE-I-HUA/antitrust/blob/CHRIS/Opn_Coun_Jud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iMIYSqHP2gc",
        "outputId": "b2d9d270-4320-41ef-a32b-6c9335c64ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "完成：/content/drive/MyDrive/textmining/opinion/opinion_Surperior.csv\n",
            "Counsel 數量: 14\n",
            "Judges 數量: 26\n",
            "Opinion by 數量: 26\n"
          ]
        }
      ],
      "source": [
        "# Opinion\n",
        "import fitz\n",
        "import re\n",
        "import csv\n",
        "\n",
        "pdf_file_path = '/content/drive/MyDrive/textmining/State Surperior Court (CA) (30).PDF'\n",
        "csv_file_path = '/content/drive/MyDrive/textmining/opinion/opinion_Surperior.csv'\n",
        "\n",
        "pattern = r'(Counsel:.*?|Judges:.*?(?=Opinion by:)|Opinion by:.*?)((?=Counsel:)|(?=Judges:)|(?=Opinion by:)|(?=Opinion)|$)'\n",
        "\n",
        "def find_page_num(text, match_start, page_delimiters):\n",
        "    for i, delimiter in enumerate(page_delimiters):\n",
        "        if match_start < delimiter:\n",
        "            return i\n",
        "    return len(page_delimiters)\n",
        "\n",
        "counsel_count = 0\n",
        "judges_count = 0\n",
        "opinion_by_count = 0\n",
        "\n",
        "with fitz.open(pdf_file_path) as doc:\n",
        "    all_text = \"\"\n",
        "    page_delimiters = []\n",
        "\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        all_text += page.get_text(\"text\") + \"\\f\"\n",
        "        page_delimiters.append(len(all_text))\n",
        "\n",
        "    all_text = re.sub(r'Page \\d+ of \\d+', '', all_text)\n",
        "\n",
        "    all_text = re.sub(r'\\d+ Cal\\..*?\\*{1,4}\\d+; (?:\\d{4} )?Cal\\..*?\\*{1,4}\\d+', '', all_text)\n",
        "\n",
        "    page_text = f'頁碼 {page_num + 1}:\\n{page_text}'\n",
        "\n",
        "    with open(csv_file_path, 'w', encoding='utf-8', newline='') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow(['頁碼', '內容類型', '內容'])\n",
        "\n",
        "        matches = re.finditer(pattern, all_text, re.DOTALL)\n",
        "        for match in matches:\n",
        "            match_content = match.group(1).strip()\n",
        "            match_type = match.group(2).strip()\n",
        "            match_page = find_page_num(all_text, match.start(), page_delimiters)\n",
        "\n",
        "            if 'Counsel:' in match_content:\n",
        "                csv_writer.writerow([match_page + 1, 'Counsel', match_content])\n",
        "                counsel_count += 1\n",
        "            elif 'Judges:' in match_content:\n",
        "                csv_writer.writerow([match_page + 1, 'Judges', match_content])\n",
        "                judges_count += 1\n",
        "            elif 'Opinion by:' in match_content:\n",
        "                csv_writer.writerow([match_page + 1, 'Opinion by', match_content])\n",
        "                opinion_by_count += 1\n",
        "\n",
        "\n",
        "print(f\"完成：{csv_file_path}\")\n",
        "print(f\"Counsel 數量: {counsel_count}\")\n",
        "print(f\"Judges 數量: {judges_count}\")\n",
        "print(f\"Opinion by 數量: {opinion_by_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explain\n",
        "# !pip install PyMuPDF\n",
        "import fitz\n",
        "import re\n",
        "import csv\n",
        "\n",
        "pdf_file_path = '/content/drive/MyDrive/textmining/State Surperior Court (CA) (30).PDF'\n",
        "csv_file_path = '/content/drive/MyDrive/textmining/opinion/opinion_Surperior.csv'\n",
        "\n",
        "pattern = r'(Counsel:.*?|Judges:.*?(?=Opinion by:)|Opinion by:.*?)((?=Counsel:)|(?=Judges:)|(?=Opinion by:)|(?=Opinion)|$)'\n",
        "\n",
        "# \" (Counsel:.*?|Judges:.*?(?=Opinion by:)|Opinion by:.*?) \"  :\n",
        "# capture content of \" Counsel: \", \" Judges: \" 到 \"Opinion by:\" or \"Opinion\"\n",
        "\n",
        "# \" ((?=Counsel:)|(?=Judges:)|(?=Opinion by:)|(?=Opinion)|$) \" :\n",
        "# capture the type of the match (\"Counsel:\", \"Judges:\", \"Opinion by:\", \"Opinion\", or the end of the string).\n",
        "\n",
        "\n",
        "def find_page_num(text, match_start, page_delimiters):\n",
        "\n",
        "#找出匹配文本再PDF的頁碼. Text(整個PDF文本內容) . match_start(當前匹配文本起始位置)\n",
        "# page_delimiters(包含每頁結尾在text中的列表) 將每頁文本加入all_text並記錄長度, 每個元素代表文本結束的位置\n",
        "    for i, delimiter in enumerate(page_delimiters): # i為當前頁碼索引 從0開始\n",
        "        if match_start < delimiter: #檢查match_start是否小於delimiter  , 小於代表匹配文本位於這一頁或之前的頁面\n",
        "            return i #頁碼通常從1開始, 所以後續都會對這個索引 + 1\n",
        "    return len(page_delimiters) # 表示匹配文本位於文檔最後一頁\n",
        "\n",
        "# 加入計數器\n",
        "counsel_count = 0\n",
        "judges_count = 0\n",
        "opinion_by_count = 0\n",
        "\n",
        "with fitz.open(pdf_file_path) as doc:\n",
        "    all_text = \"\" #儲存整個文本內容\n",
        "    page_delimiters = [] #儲存每頁文本結束的列表\n",
        "\n",
        "    for page_num in range(len(doc)): #閱讀文本每一頁 . len(doc):總頁數\n",
        "        page = doc.load_page(page_num) #載入當前頁\n",
        "        all_text += page.get_text(\"text\") + \"\\f\" #從當前頁提取文本並添加到all_text中 # 使用分頁符號 \"\\f\" 作為分頁標記\n",
        "        page_delimiters.append(len(all_text))  # 在page_delimiters列表添加累積文本長度,也就是當前頁結束位置, 紀錄每頁結束的位置.\n",
        "\n",
        "    # 移除包含 \"Page \\d+ of \\d+\" 的字樣\n",
        "    all_text = re.sub(r'Page \\d+ of \\d+', '', all_text)\n",
        "\n",
        "# re.sub 查找和替換 符合正則表達式的字串, ''表示將匹配內容刪除\n",
        "# \\d+ 數字 . Page和of 為單詞 . 表 刪除 ex Page 23 of 456 將其中all_text中刪除\n",
        "\n",
        "    # 移除其他不重要的字樣\n",
        "    all_text = re.sub(r'\\d+ Cal\\..*?\\*{1,4}\\d+; (?:\\d{4} )?Cal\\..*?\\*{1,4}\\d+', '', all_text)\n",
        "\n",
        "# Cal\\. = Cal. \" .*? \" 非貪婪匹配任所有字符直到遇到後面的模式 \"\\*{1,4}\" 匹配1~4個'*' ;匹配分號\n",
        "# (?:\\d{4} ) 匹配四位數字後跟一個空格 , Cal\\..*?\\*{1,4}\\d+ 同上 匹配Cal. 後面的文字,星號,數字\n",
        "\n",
        "    # 在每段文本前加上頁碼標記\n",
        "    page_text = f'頁碼 {page_num + 1}:\\n{page_text}'\n",
        "\n",
        "    with open(csv_file_path, 'w', encoding='utf-8', newline='') as csv_file:\n",
        "      #確保文件使用utf-8編碼, newline=''為了避免在不同操作系統寫入時產生新行問題\n",
        "        csv_writer = csv.writer(csv_file) # 創建CSV寫入器,將數據輸入\n",
        "        csv_writer.writerow(['頁碼', '內容類型', '內容']) #將標題寫入\n",
        "\n",
        "        matches = re.finditer(pattern, all_text, re.DOTALL) # find all occourance of pattern in 'text'\n",
        "        for match in matches: #loop initiate matches from re.finditer\n",
        "            match_content = match.group(1).strip() # 提取第一個匹配組內容,去除首尾空格\n",
        "            match_type = match.group(2).strip()  # 提取第二個匹配組內容,去除首尾空格\n",
        "            match_page = find_page_num(all_text, match.start(), page_delimiters)\n",
        "            # 調用find_page_num函數確定匹配內容所在頁碼,將這些資訊寫入CSV\n",
        "\n",
        "            if 'Counsel:' in match_content:\n",
        "                csv_writer.writerow([match_page + 1, 'Counsel', match_content])\n",
        "                counsel_count += 1\n",
        "            elif 'Judges:' in match_content:\n",
        "                csv_writer.writerow([match_page + 1, 'Judges', match_content])\n",
        "                judges_count += 1\n",
        "            elif 'Opinion by:' in match_content:\n",
        "                csv_writer.writerow([match_page + 1, 'Opinion by', match_content])\n",
        "                opinion_by_count += 1\n",
        "\n",
        "print(f\"完成：{csv_file_path}\")\n",
        "print(f\"Counsel 數量: {counsel_count}\")\n",
        "print(f\"Judges 數量: {judges_count}\")\n",
        "print(f\"Opinion by 數量: {opinion_by_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kndgiv96am3L",
        "outputId": "e746a6d5-7cf0-4f11-e739-39cdf7e9d40c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "完成：/content/drive/MyDrive/textmining/opinion/opinion_Surperior.csv\n",
            "Counsel 數量: 14\n",
            "Judges 數量: 26\n",
            "Opinion by 數量: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bzElxc_ONCM9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}